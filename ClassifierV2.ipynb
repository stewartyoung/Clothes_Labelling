{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier V2\n",
    "\n",
    "The Goal: Use the brightness levels of pixels in the image dataset to classify types of fashion items.\n",
    "\n",
    "Useful links:   \n",
    "https://towardsdatascience.com/the-4-convolutional-neural-network-models-that-can-classify-your-fashion-images-9fe7f3e5399d\n",
    "https://github.com/khanhnamle1994/fashion-mnist/blob/master/CNN-1Conv.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Split Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Keras libraries\n",
    "from tensorflow.python import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data into dataframes\n",
    "data_train = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('data/fashion-mnist_test.csv')\n",
    "\n",
    "# X forms the training images, and y forms the training labels\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "# split original training data to sub-training (80%) and validation data (20%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "# X_test forms the test images, and y_test forms the test labels\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalise the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image's dimension is 28 x 28\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Prepare the training images\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "\n",
    "# Prepare the test images\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "\n",
    "# Prepare the validation images\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.astype('float32')\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN with 1 Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN takes as input tensors of shape (image_height, image_width, image_channels) where image channels ware 1 if pixel brightness is given, or would be 3 if rgb of each pixel were given. In this case, configure the CNN to process inputs of size (28, 28, 1), the FashionMNIST images. Do this by passing the argument input_shape=(28, 28, 1) to the first layer.\n",
    "* The 1st layer is a Conv2D layer for the convolution operation that extracts features from the input images by sliding a convolution filter over the input to produce a feature map. Here choose feature map with size 5 x 5.\n",
    "* The 2nd layer is a MaxPooling2D layer for the max-pooling operation that reduces the dimensionality of each feature, which helps shorten training time and reduce number of parameters. Here choose the pooling window with size 2 x 2.\n",
    "* To combat overfititng, add a Dropout layer as the 3rd layer, a powerful regularization technique. Dropout is the method used to reduce overfitting, whcih forces the model to learn multiple independent representations of the same data by randomly disabling neurons in the learning phase. In this model, dropout will randomnly disable 20% of the neurons.\n",
    "* The next step is to feed the last output tensor into a stack of Dense layers, otherwise known as fully-connected layers. These densely connected classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. Thus, need to flatten the 3D outputs to 1D, and then add 2 Dense layers on top.\n",
    "* Do a 10-way classification (as there are 10 classes of fashion images), using a final layer with 10 outputs and a softmax activation. Softmax activation enables calculation of the output based on probabilities. Each class is assigned a probability and the class with the maximum probability is the modelâ€™s output for the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "cnn1 = Sequential()\n",
    "cnn1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "cnn1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn1.add(Dropout(0.2))\n",
    "\n",
    "cnn1.add(Flatten())\n",
    "\n",
    "cnn1.add(Dense(128, activation='relu'))\n",
    "cnn1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
